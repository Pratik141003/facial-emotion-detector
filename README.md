# Facial Emotion Detection & Landmark Tracking System

This project is a real-time facial emotion recognition and landmark detection system using deep learning (TensorFlow/Keras) and MediaPipe. It allows for detecting human emotions such as Happy, Sad, Angry, etc., directly from live webcam footage, while also overlaying facial landmarks.

---

## ğŸ“Œ Features

- ğŸ¯ **Real-Time Emotion Recognition** using webcam input
- ğŸ’¡ **Deep Learning-Based CNN Model** trained on grayscale face images
- ğŸ§  Fine-tuning support using **MobileNetV2**
- ğŸ§â€â™‚ï¸ Facial landmark detection using **MediaPipe FaceMesh**
- ğŸ“ˆ Class weighting for imbalanced datasets
- ğŸ—‚ Modular code for easy training, testing, and inference

---

## ğŸ“ Project Structure

facial-emotion-detector/
â”‚
â”œâ”€â”€ dataset/ 
â”œâ”€â”€ models/ # Trained models (train_emotion_model.h5 )
â”‚
â”œâ”€â”€ main_app.py # Run this for real-time webcam emotion detection
â”œâ”€â”€ landmark_detector.py # Test only landmark detection
â”œâ”€â”€ train_emotion_model.py # Train CNN model from scratch
â”œâ”€â”€ fine_tune_custom_model.py # Fine-tune MobileNetV2 on your dataset
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # Project overview



---

## ğŸš€ How to Run

### ğŸ”§ 1. Install Requirements

Create and activate a virtual environment (optional but recommended):

```bash
python -m venv env
env\Scripts\activate       # On Windows
source env/bin/activate    # On Linux/Mac

Install dependencies:
pip install -r requirements.txt

 Train from Scratch:
python train_emotion_model.py

 Fine-Tune with MobileNetV2:
python fine_tune_custom_model.py

Run Real-Time Emotion Detection
python main_app.py

Run Landmark Detection Only
python landmark_detector.py

Emotion Classes Used:
['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']

Technologies Used:

Python 3.x
TensorFlow / Keras
OpenCV
MediaPipe
NumPy
Matplotlib
scikit-learn

